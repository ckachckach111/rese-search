import streamlit as st
import pandas as pd
import re
import unicodedata

# -------------------------
# ë°ì´í„° ë¡œë“œ (ì¸ì½”ë”© ì•ˆì „)
# -------------------------
@st.cache_data
def load_data(path="accounts.csv"):
    for enc in ("utf-8-sig", "utf-8", "cp949", "euc-kr"):
        try:
            return pd.read_csv(path, encoding=enc)
        except Exception:
            continue
    return pd.DataFrame()

df = load_data()
if df.empty:
    st.error("accounts.csvë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# -------------------------
# ì»¬ëŸ¼ ì´ë¦„ ë³´ì •
# -------------------------
df.columns = [c.strip().replace("ìºë¦­í„°ëª©ë¡", "ìºë¦­í„° ëª©ë¡") for c in df.columns]
required = ["ë²ˆí˜¸", "í•œì •", "ê°€ê²©", "ìºë¦­í„° ëª©ë¡"]
if any(c not in df.columns for c in required):
    st.error(f"CSV ì»¬ëŸ¼ ì˜¤ë¥˜ / í•„ìš”: {required}")
    st.stop()

# -------------------------
# ê²€ìƒ‰ìš© í† í° ì²˜ë¦¬ (ê¸°ì¡´ ìœ ì§€)
# -------------------------
def normalize_text_for_tokens(s: str):
    if not isinstance(s, str):
        return []
    s = unicodedata.normalize("NFKC", s)
    s = re.sub(r'\(\+\s*\d+\s*\)|\+\s*\d+|\b[45]\s*ì„±\b', ' ', s)
    s = re.sub(r'[^\wê°€-í£]', ' ', s)
    s = re.sub(r'\s+', ' ', s).strip()
    return re.findall(r'[ê°€-í£]+|[A-Za-z0-9]+', s.lower())

def normalize_search_terms(q: str):
    if not q:
        return []
    return [re.sub(r'[^\wê°€-í£]', '', t.lower()) for t in q.split() if t.strip()]

df["ìºë¦­í„° ëª©ë¡"] = df["ìºë¦­í„° ëª©ë¡"].fillna("").astype(str)
df["_tokens"] = df["ìºë¦­í„° ëª©ë¡"].apply(normalize_text_for_tokens)

# -------------------------
# íŒ¨ìŠ¤ ê°¯ìˆ˜: CSV ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
# -------------------------
pass_col = next((c for c in ["íŒ¨ìŠ¤ ê°¯ìˆ˜", "íŒ¨ìŠ¤", "íŒ¨ìŠ¤ê°¯ìˆ˜"] if c in df.columns), None)
df["íŒ¨ìŠ¤"] = pd.to_numeric(df[pass_col], errors="coerce").fillna(0).astype(int) if pass_col else 0

# -------------------------
# UI
# -------------------------
st.set_page_config(page_title="ê³„ì • ê²€ìƒ‰", layout="wide")
st.markdown("<h2 style='text-align:center;'>ğŸ® ê³„ì • ê²€ìƒ‰</h2>", unsafe_allow_html=True)

# -------------------------
# ê²€ìƒ‰ ì¡°ê±´
# -------------------------
query = st.text_input("", placeholder="ì˜ˆ: íˆë§ˆë¦¬ íˆì¹´ë¦¬ (ë„ì–´ì“°ê¸° AND ê²€ìƒ‰)")
min_price, max_price = st.slider("ê°€ê²©ëŒ€ (ë§Œì›)", 0, 100, (0, 100))
min_limit = st.number_input("ìµœì†Œ í•œì • ìºë¦­í„° ìˆ˜", 0, 100, 0)

min_pass, max_pass = st.slider(
    "íŒ¨ìŠ¤ ê°¯ìˆ˜",
    int(df["íŒ¨ìŠ¤"].min()),
    int(df["íŒ¨ìŠ¤"].max()),
    (int(df["íŒ¨ìŠ¤"].min()), int(df["íŒ¨ìŠ¤"].max()))
)

# -------------------------
# ê²€ìƒ‰ ì‹¤í–‰
# -------------------------
if st.button("ê²€ìƒ‰"):
    result = df.copy()

    result["ê°€ê²©"] = pd.to_numeric(result["ê°€ê²©"], errors="coerce")
    result = result[(result["ê°€ê²©"] >= min_price) & (result["ê°€ê²©"] <= max_price)]

    result["í•œì •"] = pd.to_numeric(result["í•œì •"], errors="coerce").fillna(0)
    result = result[result["í•œì •"] >= min_limit]

    result = result[(result["íŒ¨ìŠ¤"] >= min_pass) & (result["íŒ¨ìŠ¤"] <= max_pass)]

    terms = normalize_search_terms(query)
    if terms:
        result = result[result["_tokens"].apply(lambda t: all(x in t for x in terms))]

    if not result.empty:
        st.write(f"ì´ {len(result)}ê°œ ê³„ì •")
        st.dataframe(
            result[["ë²ˆí˜¸", "í•œì •", "ê°€ê²©", "íŒ¨ìŠ¤", "ìºë¦­í„° ëª©ë¡"]],
            use_container_width=True,
            height=700
        )
    else:
        st.warning("ì¡°ê±´ì— ë§ëŠ” ê³„ì •ì´ ì—†ìŠµë‹ˆë‹¤.")

# -------------------------
# ì‚¬ìš© ì„¤ëª…
# -------------------------
st.markdown("""
---
### ì‚¬ìš© ë°©ë²•
- ìºë¦­í„° ì´ë¦„ì€ **ë„ì–´ì“°ê¸°ë¡œ AND ê²€ìƒ‰**
- ê°€ê²© ë‹¨ìœ„ëŠ” **ë§Œì›**
- **íŒ¨ìŠ¤ ê°¯ìˆ˜ëŠ” CSVì— ì íŒ ìˆ«ìë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©**
- ê²°ê³¼ í‘œ ì»¬ëŸ¼ ìˆœì„œ:
  **ë²ˆí˜¸ / í•œì • / ê°€ê²© / íŒ¨ìŠ¤ / ìºë¦­í„° ëª©ë¡**
""")
